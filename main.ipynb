{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shubhii0206/Adaptive-Graph-Pooling-for-Protein-Structure-Classification-Using-GCNs/blob/main/main.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# D&D Binary Classification"
      ],
      "metadata": {
        "id": "5NsiFQnOAQHI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch torchvision torch-geometric"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gFyMmVUPn1Ll",
        "outputId": "88160932-8203-44ea-ad33-9457a937d234"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.1+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.20.1+cu121)\n",
            "Collecting torch-geometric\n",
            "  Downloading torch_geometric-2.6.1-py3-none-any.whl.metadata (63 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.1/63.1 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.26.4)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (11.0.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.11.9)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (5.9.5)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.2.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (4.66.6)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (1.3.1)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (4.0.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (1.18.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (2024.8.30)\n",
            "Downloading torch_geometric-2.6.1-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m17.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: torch-geometric\n",
            "Successfully installed torch-geometric-2.6.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch_geometric.datasets import TUDataset\n",
        "from torch_geometric.loader import DataLoader\n",
        "dataset = TUDataset(root='data/DD', name='DD')"
      ],
      "metadata": {
        "id": "mdg27fVCj0RG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c0ecd0ff-24d0-4da6-8c91-52ed136e7580"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading https://www.chrsmrrs.com/graphkerneldatasets/DD.zip\n",
            "Processing...\n",
            "Done!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import GCNConv, TopKPooling, global_mean_pool\n",
        "from torch_geometric.nn import global_mean_pool as gap, global_max_pool as gmp\n",
        "from torch_geometric.nn import DenseGCNConv as GCNConv, dense_diff_pool as DiffPool"
      ],
      "metadata": {
        "id": "CeYpUdbvw9hc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_size = int(0.8 * len(dataset))\n",
        "test_size = len(dataset) - train_size\n",
        "train_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, test_size])\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=3, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=3, shuffle=False)"
      ],
      "metadata": {
        "id": "9W47IepQoGWV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for data in train_loader:\n",
        "  print(data.x.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "m0GlzkQ13bvy",
        "outputId": "f3cd996c-872b-4ff6-ca13-dc270c74b565"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([619, 89])\n",
            "torch.Size([521, 89])\n",
            "torch.Size([707, 89])\n",
            "torch.Size([825, 89])\n",
            "torch.Size([743, 89])\n",
            "torch.Size([862, 89])\n",
            "torch.Size([1107, 89])\n",
            "torch.Size([806, 89])\n",
            "torch.Size([1065, 89])\n",
            "torch.Size([430, 89])\n",
            "torch.Size([797, 89])\n",
            "torch.Size([467, 89])\n",
            "torch.Size([1100, 89])\n",
            "torch.Size([1161, 89])\n",
            "torch.Size([823, 89])\n",
            "torch.Size([1214, 89])\n",
            "torch.Size([961, 89])\n",
            "torch.Size([538, 89])\n",
            "torch.Size([796, 89])\n",
            "torch.Size([768, 89])\n",
            "torch.Size([580, 89])\n",
            "torch.Size([730, 89])\n",
            "torch.Size([455, 89])\n",
            "torch.Size([924, 89])\n",
            "torch.Size([602, 89])\n",
            "torch.Size([730, 89])\n",
            "torch.Size([777, 89])\n",
            "torch.Size([895, 89])\n",
            "torch.Size([577, 89])\n",
            "torch.Size([685, 89])\n",
            "torch.Size([711, 89])\n",
            "torch.Size([643, 89])\n",
            "torch.Size([968, 89])\n",
            "torch.Size([723, 89])\n",
            "torch.Size([591, 89])\n",
            "torch.Size([483, 89])\n",
            "torch.Size([1415, 89])\n",
            "torch.Size([1465, 89])\n",
            "torch.Size([1693, 89])\n",
            "torch.Size([845, 89])\n",
            "torch.Size([576, 89])\n",
            "torch.Size([642, 89])\n",
            "torch.Size([651, 89])\n",
            "torch.Size([675, 89])\n",
            "torch.Size([491, 89])\n",
            "torch.Size([522, 89])\n",
            "torch.Size([1545, 89])\n",
            "torch.Size([559, 89])\n",
            "torch.Size([1052, 89])\n",
            "torch.Size([939, 89])\n",
            "torch.Size([6530, 89])\n",
            "torch.Size([2054, 89])\n",
            "torch.Size([526, 89])\n",
            "torch.Size([675, 89])\n",
            "torch.Size([1282, 89])\n",
            "torch.Size([1226, 89])\n",
            "torch.Size([664, 89])\n",
            "torch.Size([1445, 89])\n",
            "torch.Size([1015, 89])\n",
            "torch.Size([472, 89])\n",
            "torch.Size([1009, 89])\n",
            "torch.Size([449, 89])\n",
            "torch.Size([897, 89])\n",
            "torch.Size([626, 89])\n",
            "torch.Size([696, 89])\n",
            "torch.Size([716, 89])\n",
            "torch.Size([809, 89])\n",
            "torch.Size([916, 89])\n",
            "torch.Size([513, 89])\n",
            "torch.Size([1027, 89])\n",
            "torch.Size([516, 89])\n",
            "torch.Size([974, 89])\n",
            "torch.Size([1108, 89])\n",
            "torch.Size([835, 89])\n",
            "torch.Size([464, 89])\n",
            "torch.Size([793, 89])\n",
            "torch.Size([1016, 89])\n",
            "torch.Size([506, 89])\n",
            "torch.Size([715, 89])\n",
            "torch.Size([619, 89])\n",
            "torch.Size([791, 89])\n",
            "torch.Size([950, 89])\n",
            "torch.Size([1017, 89])\n",
            "torch.Size([817, 89])\n",
            "torch.Size([619, 89])\n",
            "torch.Size([1427, 89])\n",
            "torch.Size([989, 89])\n",
            "torch.Size([1237, 89])\n",
            "torch.Size([905, 89])\n",
            "torch.Size([1344, 89])\n",
            "torch.Size([461, 89])\n",
            "torch.Size([424, 89])\n",
            "torch.Size([590, 89])\n",
            "torch.Size([778, 89])\n",
            "torch.Size([1021, 89])\n",
            "torch.Size([725, 89])\n",
            "torch.Size([1464, 89])\n",
            "torch.Size([860, 89])\n",
            "torch.Size([377, 89])\n",
            "torch.Size([575, 89])\n",
            "torch.Size([645, 89])\n",
            "torch.Size([592, 89])\n",
            "torch.Size([1217, 89])\n",
            "torch.Size([1123, 89])\n",
            "torch.Size([545, 89])\n",
            "torch.Size([545, 89])\n",
            "torch.Size([1304, 89])\n",
            "torch.Size([893, 89])\n",
            "torch.Size([1474, 89])\n",
            "torch.Size([941, 89])\n",
            "torch.Size([1047, 89])\n",
            "torch.Size([394, 89])\n",
            "torch.Size([806, 89])\n",
            "torch.Size([1023, 89])\n",
            "torch.Size([348, 89])\n",
            "torch.Size([904, 89])\n",
            "torch.Size([755, 89])\n",
            "torch.Size([1004, 89])\n",
            "torch.Size([1206, 89])\n",
            "torch.Size([987, 89])\n",
            "torch.Size([825, 89])\n",
            "torch.Size([721, 89])\n",
            "torch.Size([510, 89])\n",
            "torch.Size([790, 89])\n",
            "torch.Size([580, 89])\n",
            "torch.Size([616, 89])\n",
            "torch.Size([493, 89])\n",
            "torch.Size([752, 89])\n",
            "torch.Size([1187, 89])\n",
            "torch.Size([773, 89])\n",
            "torch.Size([728, 89])\n",
            "torch.Size([559, 89])\n",
            "torch.Size([543, 89])\n",
            "torch.Size([651, 89])\n",
            "torch.Size([879, 89])\n",
            "torch.Size([703, 89])\n",
            "torch.Size([1052, 89])\n",
            "torch.Size([882, 89])\n",
            "torch.Size([501, 89])\n",
            "torch.Size([634, 89])\n",
            "torch.Size([1205, 89])\n",
            "torch.Size([410, 89])\n",
            "torch.Size([747, 89])\n",
            "torch.Size([886, 89])\n",
            "torch.Size([724, 89])\n",
            "torch.Size([558, 89])\n",
            "torch.Size([380, 89])\n",
            "torch.Size([851, 89])\n",
            "torch.Size([330, 89])\n",
            "torch.Size([1524, 89])\n",
            "torch.Size([855, 89])\n",
            "torch.Size([758, 89])\n",
            "torch.Size([791, 89])\n",
            "torch.Size([738, 89])\n",
            "torch.Size([976, 89])\n",
            "torch.Size([1138, 89])\n",
            "torch.Size([958, 89])\n",
            "torch.Size([1217, 89])\n",
            "torch.Size([851, 89])\n",
            "torch.Size([474, 89])\n",
            "torch.Size([622, 89])\n",
            "torch.Size([970, 89])\n",
            "torch.Size([794, 89])\n",
            "torch.Size([1331, 89])\n",
            "torch.Size([1567, 89])\n",
            "torch.Size([451, 89])\n",
            "torch.Size([830, 89])\n",
            "torch.Size([732, 89])\n",
            "torch.Size([662, 89])\n",
            "torch.Size([1258, 89])\n",
            "torch.Size([858, 89])\n",
            "torch.Size([387, 89])\n",
            "torch.Size([972, 89])\n",
            "torch.Size([871, 89])\n",
            "torch.Size([1032, 89])\n",
            "torch.Size([865, 89])\n",
            "torch.Size([634, 89])\n",
            "torch.Size([837, 89])\n",
            "torch.Size([1192, 89])\n",
            "torch.Size([620, 89])\n",
            "torch.Size([1264, 89])\n",
            "torch.Size([405, 89])\n",
            "torch.Size([928, 89])\n",
            "torch.Size([561, 89])\n",
            "torch.Size([257, 89])\n",
            "torch.Size([876, 89])\n",
            "torch.Size([691, 89])\n",
            "torch.Size([828, 89])\n",
            "torch.Size([524, 89])\n",
            "torch.Size([945, 89])\n",
            "torch.Size([267, 89])\n",
            "torch.Size([661, 89])\n",
            "torch.Size([560, 89])\n",
            "torch.Size([872, 89])\n",
            "torch.Size([1187, 89])\n",
            "torch.Size([646, 89])\n",
            "torch.Size([512, 89])\n",
            "torch.Size([580, 89])\n",
            "torch.Size([395, 89])\n",
            "torch.Size([1154, 89])\n",
            "torch.Size([435, 89])\n",
            "torch.Size([818, 89])\n",
            "torch.Size([655, 89])\n",
            "torch.Size([700, 89])\n",
            "torch.Size([670, 89])\n",
            "torch.Size([953, 89])\n",
            "torch.Size([1224, 89])\n",
            "torch.Size([755, 89])\n",
            "torch.Size([808, 89])\n",
            "torch.Size([751, 89])\n",
            "torch.Size([485, 89])\n",
            "torch.Size([473, 89])\n",
            "torch.Size([801, 89])\n",
            "torch.Size([1080, 89])\n",
            "torch.Size([635, 89])\n",
            "torch.Size([772, 89])\n",
            "torch.Size([989, 89])\n",
            "torch.Size([1112, 89])\n",
            "torch.Size([761, 89])\n",
            "torch.Size([897, 89])\n",
            "torch.Size([1193, 89])\n",
            "torch.Size([710, 89])\n",
            "torch.Size([1047, 89])\n",
            "torch.Size([608, 89])\n",
            "torch.Size([1158, 89])\n",
            "torch.Size([858, 89])\n",
            "torch.Size([991, 89])\n",
            "torch.Size([4660, 89])\n",
            "torch.Size([1061, 89])\n",
            "torch.Size([732, 89])\n",
            "torch.Size([1227, 89])\n",
            "torch.Size([718, 89])\n",
            "torch.Size([978, 89])\n",
            "torch.Size([1051, 89])\n",
            "torch.Size([817, 89])\n",
            "torch.Size([3373, 89])\n",
            "torch.Size([478, 89])\n",
            "torch.Size([516, 89])\n",
            "torch.Size([808, 89])\n",
            "torch.Size([597, 89])\n",
            "torch.Size([931, 89])\n",
            "torch.Size([639, 89])\n",
            "torch.Size([1515, 89])\n",
            "torch.Size([816, 89])\n",
            "torch.Size([647, 89])\n",
            "torch.Size([826, 89])\n",
            "torch.Size([1309, 89])\n",
            "torch.Size([673, 89])\n",
            "torch.Size([604, 89])\n",
            "torch.Size([447, 89])\n",
            "torch.Size([566, 89])\n",
            "torch.Size([556, 89])\n",
            "torch.Size([1342, 89])\n",
            "torch.Size([629, 89])\n",
            "torch.Size([523, 89])\n",
            "torch.Size([514, 89])\n",
            "torch.Size([749, 89])\n",
            "torch.Size([1015, 89])\n",
            "torch.Size([596, 89])\n",
            "torch.Size([924, 89])\n",
            "torch.Size([917, 89])\n",
            "torch.Size([1162, 89])\n",
            "torch.Size([1281, 89])\n",
            "torch.Size([935, 89])\n",
            "torch.Size([696, 89])\n",
            "torch.Size([933, 89])\n",
            "torch.Size([860, 89])\n",
            "torch.Size([662, 89])\n",
            "torch.Size([335, 89])\n",
            "torch.Size([727, 89])\n",
            "torch.Size([660, 89])\n",
            "torch.Size([515, 89])\n",
            "torch.Size([754, 89])\n",
            "torch.Size([928, 89])\n",
            "torch.Size([1614, 89])\n",
            "torch.Size([500, 89])\n",
            "torch.Size([736, 89])\n",
            "torch.Size([623, 89])\n",
            "torch.Size([1842, 89])\n",
            "torch.Size([541, 89])\n",
            "torch.Size([815, 89])\n",
            "torch.Size([415, 89])\n",
            "torch.Size([911, 89])\n",
            "torch.Size([839, 89])\n",
            "torch.Size([829, 89])\n",
            "torch.Size([866, 89])\n",
            "torch.Size([980, 89])\n",
            "torch.Size([784, 89])\n",
            "torch.Size([1102, 89])\n",
            "torch.Size([867, 89])\n",
            "torch.Size([509, 89])\n",
            "torch.Size([569, 89])\n",
            "torch.Size([513, 89])\n",
            "torch.Size([773, 89])\n",
            "torch.Size([909, 89])\n",
            "torch.Size([363, 89])\n",
            "torch.Size([603, 89])\n",
            "torch.Size([876, 89])\n",
            "torch.Size([566, 89])\n",
            "torch.Size([664, 89])\n",
            "torch.Size([611, 89])\n",
            "torch.Size([783, 89])\n",
            "torch.Size([880, 89])\n",
            "torch.Size([1005, 89])\n",
            "torch.Size([1757, 89])\n",
            "torch.Size([1161, 89])\n",
            "torch.Size([822, 89])\n",
            "torch.Size([553, 89])\n",
            "torch.Size([606, 89])\n",
            "torch.Size([796, 89])\n",
            "torch.Size([613, 89])\n",
            "torch.Size([737, 89])\n",
            "torch.Size([783, 89])\n",
            "torch.Size([375, 89])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Architecture"
      ],
      "metadata": {
        "id": "EnOOpV9lxVIk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import GCNConv, TopKPooling, global_mean_pool\n",
        "\n",
        "class DiffPoolLayer(torch.nn.Module):\n",
        "  def __init__(self, in_channels, hidden_channels, num_clusters):\n",
        "    super(DiffPoolLayer, self).__init__()\n",
        "    # GNN for learning node embeddings\n",
        "    self.gnn_embed = GCNConv(in_channels, hidden_channels)\n",
        "    # GNN for learning cluster assignments\n",
        "    self.gnn_assign = GCNConv(in_channels, num_clusters)\n",
        "\n",
        "  def forward(self, x, edge_index, batch):\n",
        "    # Learn node embeddings\n",
        "    h = F.relu(self.gnn_embed(x, edge_index))\n",
        "    # Learn assignment matrix (cluster assignments)\n",
        "    s = torch.softmax(self.gnn_assign(x, edge_index), dim=-1)\n",
        "\n",
        "    # Pooling: Aggregate node features into clusters\n",
        "    x_pooled = torch.matmul(s.T, h)  # (num_clusters, hidden_channels)\n",
        "\n",
        "    # New adjacency matrix after coarsening\n",
        "    adj_pooled = torch.matmul(s.T, s)  # (num_clusters, num_clusters)\n",
        "\n",
        "    # Reconstruct edge_index from pooled adjacency matrix\n",
        "    edge_index_pooled = (adj_pooled > 0).nonzero(as_tuple=False).T\n",
        "\n",
        "    # Batch update: assume each cluster belongs to the same graph as the original nodes\n",
        "    num_graphs = batch.max().item() + 1\n",
        "    clusters_per_graph = max(1, s.shape[1] // num_graphs)\n",
        "\n",
        "    batch_pooled = torch.repeat_interleave(torch.arange(num_graphs), clusters_per_graph)[:s.shape[1]]\n",
        "\n",
        "    #batch_pooled = torch.repeat_interleave(torch.arange(batch.max() + 1), s.shape[1] // (batch.max() + 1))\n",
        "    #assert x.size(0) == batch.max().item() + 1, \"Batch size mismatch!\"\n",
        "    if (batch_pooled.size() == 2):\n",
        "      batch_pooled += 1\n",
        "    return x_pooled, edge_index_pooled, batch_pooled\n",
        "\n",
        "class GraphClassificationModel(torch.nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, num_classes, m1, m2, k1=0.2, k2=0.1):\n",
        "      super(GraphClassificationModel, self).__init__()\n",
        "\n",
        "      # GNN Layers\n",
        "      self.gnn1 = GCNConv(input_dim, hidden_dim)\n",
        "      self.gnn2 = GCNConv(hidden_dim, hidden_dim)\n",
        "\n",
        "      # gPool Layer 1\n",
        "      self.pool1 = TopKPooling(hidden_dim, ratio=k1)\n",
        "\n",
        "      # DiffPool Layer 1\n",
        "      self.diffpool1 = DiffPoolLayer(hidden_dim, hidden_dim, m1)\n",
        "\n",
        "      self.gnn3 = GCNConv(hidden_dim, hidden_dim)\n",
        "      self.gnn4 = GCNConv(hidden_dim, hidden_dim)\n",
        "\n",
        "      # gPool Layer 2\n",
        "      self.pool2 = TopKPooling(hidden_dim, ratio=k2)\n",
        "\n",
        "      # DiffPool Layer 2\n",
        "      self.diffpool2 = DiffPoolLayer(hidden_dim, hidden_dim, m2)\n",
        "\n",
        "      # Final classification layer\n",
        "      self.fc = torch.nn.Linear(hidden_dim, num_classes)\n",
        "\n",
        "    def forward(self, data):\n",
        "      x, edge_index, batch = data.x, data.edge_index, data.batch\n",
        "\n",
        "      # Initial GNN Layers\n",
        "      x = F.relu(self.gnn1(x, edge_index))\n",
        "      x = F.relu(self.gnn2(x, edge_index))\n",
        "      # print(f\"Starting: x size = {x.size()}, batch size = {batch.size()}\")\n",
        "      # print(\"-------------------------------------\")\n",
        "      # gPool Layer 1\n",
        "      # Modified: Unpack only the necessary values\n",
        "      x, edge_index, _, batch, perm, score = self.pool1(x, edge_index, None, batch)\n",
        "      # print(f\"After gpool1: x size = {x.size()}, batch size = {batch.size()}\")\n",
        "      # print(\"-------------------------------------\")\n",
        "      # print(f\"batch size: {batch.size()}, perm size: {perm.size()}\")\n",
        "      # print(f\"max(perm): {perm.max()}, len(batch): {len(batch)}\")\n",
        "      if perm.size(0) > 0:\n",
        "        perm = perm[perm < batch.size(0)]\n",
        "        batch = batch[perm]  # Update batch after pooling\n",
        "\n",
        "      # DiffPool Layer 1\n",
        "      x, edge_index, batch = self.diffpool1(x, edge_index, batch)\n",
        "      # print(f\"After diffpool1: x size = {x.size()}, batch size = {batch.size()}\")\n",
        "      # print(\"-------------------------------------\")\n",
        "\n",
        "      # Additional GNN Layers\n",
        "      x = F.relu(self.gnn3(x, edge_index))\n",
        "      x = F.relu(self.gnn4(x, edge_index))\n",
        "\n",
        "      # gPool Layer 2\n",
        "      # Modified: Unpack only the necessary values\n",
        "      #print(f\"After DiffPool: x size = {x.size()}, batch size = {batch.size()}\")\n",
        "\n",
        "      x, edge_index, _, batch, perm, score = self.pool2(x, edge_index, None, batch)\n",
        "      # print(f\"After gpool2: x size = {x.size()}, batch size = {batch.size()}\")\n",
        "      # print(\"-------------------------------------\")\n",
        "      # print(f\"batch size: {batch.size()}, perm size: {perm.size()}\")\n",
        "      # print(f\"max(perm): {perm.max()}, len(batch): {len(batch)}\")\n",
        "      # perm = perm[perm < batch.size(0)]\n",
        "      # batch = batch[perm]  # Update batch after pooling\n",
        "\n",
        "      # # DiffPool Layer 2\n",
        "      # x, edge_index, batch = self.diffpool2(x, edge_index, batch)\n",
        "\n",
        "      # # Global Pooling for graph-level embedding\n",
        "      # x = global_mean_pool(x, batch)\n",
        "\n",
        "       # Check for empty graphs after pooling\n",
        "      if batch.size(0) == 0:\n",
        "          # Handle empty graphs (e.g., skip or assign a default output)\n",
        "          # For example, you could return a zero vector for these graphs:\n",
        "          print(\"graph is empty\")\n",
        "          x = torch.zeros(1, self.hidden_dim, device=x.device)\n",
        "          batch = torch.zeros(1, dtype=torch.long, device=x.device)\n",
        "\n",
        "      else:\n",
        "\n",
        "          perm = perm[perm < batch.size(0)]\n",
        "          batch = batch[perm]  # Update batch after pooling\n",
        "\n",
        "      # DiffPool Layer 2\n",
        "      x, edge_index, batch = self.diffpool2(x, edge_index, batch)\n",
        "      # print(f\"After diffpool2: x size = {x.size()}, batch size = {batch.size()}\")\n",
        "      # print(\"-------------------------------------\")\n",
        "\n",
        "\n",
        "\n",
        "      # Global Pooling for graph-level embedding\n",
        "      x = global_mean_pool(x, batch)\n",
        "      # print(f\"After globalmean: x size = {x.size()}, batch size = {batch.size()}\")\n",
        "\n",
        "      # Final Classification Head\n",
        "      x = self.fc(x)\n",
        "      #print(f\"After fc: x size = {x.size()}, batch size = {batch.size()}\")\n",
        "      #print(F.log_softmax(x, dim=1))\n",
        "      return F.log_softmax(x, dim=1)\n"
      ],
      "metadata": {
        "id": "vinkhbJbxUJK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training and Evaluation Functions"
      ],
      "metadata": {
        "id": "8uXN5A9fzFXl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, loader, optimizer, criterion):\n",
        "  model.train()\n",
        "  total_loss = 0\n",
        "  for data in loader:\n",
        "    optimizer.zero_grad()\n",
        "    out = model(data)\n",
        "    loss = criterion(out, data.y)\n",
        "\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    total_loss += loss.item()\n",
        "  return total_loss / len(loader)\n",
        "\n",
        "def test(model, loader):\n",
        "  model.eval()\n",
        "  correct = 0\n",
        "  for data in loader:\n",
        "    out = model(data)\n",
        "\n",
        "    pred = out.argmax(dim=1)\n",
        "    correct += int((pred == data.y).sum())\n",
        "  return correct / len(loader.dataset)"
      ],
      "metadata": {
        "id": "IB-kvyhlzJBd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Experimenting with Different Hyperparameters"
      ],
      "metadata": {
        "id": "P9gM7y_oxLCP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the model with specific hyperparameters\n",
        "model = GraphClassificationModel(\n",
        "    input_dim=dataset.num_node_features,\n",
        "    hidden_dim=64,  # Adjust as needed\n",
        "    num_classes=dataset.num_classes,\n",
        "    m1=6,  # First DiffPool with 6 clusters\n",
        "    m2=3,  # Second DiffPool with 3 clusters\n",
        "    k1=0.9,  # 90% top nodes kept in first gPool layer\n",
        "    k2=0.8   # 80% top nodes kept in second gPool layer\n",
        ")\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "for epoch in range(1, 31):\n",
        "  train_loss = train(model, train_loader, optimizer, criterion)\n",
        "  train_acc = test(model, train_loader)\n",
        "  #test_acc = test(model, test_loader)\n",
        "  print(f'Epoch: {epoch}, Train Loss: {train_loss:.4f}, Test Accuracy: {train_acc:.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8f1LdkcxTYxT",
        "outputId": "59fc7836-cc31-444a-a975-fb2bf4ee3c2a",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1, Train Loss: 0.7154, Test Accuracy: 0.5807\n",
            "Epoch: 2, Train Loss: 0.6815, Test Accuracy: 0.5807\n",
            "Epoch: 3, Train Loss: 0.6822, Test Accuracy: 0.5807\n",
            "Epoch: 4, Train Loss: 0.6820, Test Accuracy: 0.5807\n",
            "Epoch: 5, Train Loss: 0.6819, Test Accuracy: 0.5807\n",
            "Epoch: 6, Train Loss: 0.6819, Test Accuracy: 0.5807\n",
            "Epoch: 7, Train Loss: 0.6825, Test Accuracy: 0.5807\n",
            "Epoch: 8, Train Loss: 0.6820, Test Accuracy: 0.5807\n",
            "Epoch: 9, Train Loss: 0.6819, Test Accuracy: 0.5807\n",
            "Epoch: 10, Train Loss: 0.6823, Test Accuracy: 0.5807\n",
            "Epoch: 11, Train Loss: 0.6818, Test Accuracy: 0.5807\n",
            "Epoch: 12, Train Loss: 0.6821, Test Accuracy: 0.5807\n",
            "Epoch: 13, Train Loss: 0.6823, Test Accuracy: 0.5807\n",
            "Epoch: 14, Train Loss: 0.6798, Test Accuracy: 0.5807\n",
            "Epoch: 15, Train Loss: 0.6825, Test Accuracy: 0.5807\n",
            "Epoch: 16, Train Loss: 0.6822, Test Accuracy: 0.5807\n",
            "Epoch: 17, Train Loss: 0.6834, Test Accuracy: 0.5807\n",
            "Epoch: 18, Train Loss: 0.6815, Test Accuracy: 0.5807\n",
            "Epoch: 19, Train Loss: 0.6818, Test Accuracy: 0.5807\n",
            "Epoch: 20, Train Loss: 0.6810, Test Accuracy: 0.5807\n",
            "Epoch: 21, Train Loss: 0.6807, Test Accuracy: 0.5807\n",
            "Epoch: 22, Train Loss: 0.6826, Test Accuracy: 0.5807\n",
            "Epoch: 23, Train Loss: 0.6828, Test Accuracy: 0.5807\n",
            "Epoch: 24, Train Loss: 0.6833, Test Accuracy: 0.5807\n",
            "Epoch: 25, Train Loss: 0.6819, Test Accuracy: 0.5807\n",
            "Epoch: 26, Train Loss: 0.6835, Test Accuracy: 0.5807\n",
            "Epoch: 27, Train Loss: 0.6824, Test Accuracy: 0.5807\n",
            "Epoch: 28, Train Loss: 0.6821, Test Accuracy: 0.5807\n",
            "Epoch: 29, Train Loss: 0.6817, Test Accuracy: 0.5807\n",
            "Epoch: 30, Train Loss: 0.6821, Test Accuracy: 0.5807\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for batch in train_loader:\n",
        "  print(f\"Number of graphs in batch: {batch.num_graphs}\")\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "z-CpeZuL2OBh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_dim = dataset.num_node_features\n",
        "hidden_dim = 64\n",
        "num_classes = 2\n",
        "\n",
        "k_values = [0.9, 0.8, 0.6]\n",
        "results = {}\n",
        "\n",
        "for k1 in k_values:\n",
        "  for k2 in k_values:\n",
        "    if k1 == k2:\n",
        "      continue\n",
        "    model = GraphClassificationModel(input_dim, hidden_dim, num_classes, m1=6, m2=3, k1=k1, k2=k2)\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
        "    criterion = torch.nn.CrossEntropyLoss()\n",
        "    print(f\"k1 = {k1} and k2 = {k2}\")\n",
        "    for epoch in range(1, 11):\n",
        "      train_loss = train(model, train_loader, optimizer, criterion)\n",
        "      test_acc = test(model, train_loader)\n",
        "      print(f'Epoch: {epoch}, Train Loss: {train_loss:.4f}, Test Accuracy: {test_acc:.4f}')\n",
        "      results[(k1, k2)] = test_acc\n",
        "    print(f'Final Test Accuracy with k1={k1}, k2={k2}: {test_acc:.4f}\\n')"
      ],
      "metadata": {
        "id": "uZ4JHxjFz6RT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6ba0ea57-9a13-4c0f-ddc7-b41d923f6605"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "k1 = 0.9 and k2 = 0.8\n",
            "Epoch: 1, Train Loss: 0.6984, Test Accuracy: 0.5786\n",
            "Epoch: 2, Train Loss: 0.6827, Test Accuracy: 0.5786\n",
            "Epoch: 3, Train Loss: 0.6827, Test Accuracy: 0.5786\n",
            "Epoch: 4, Train Loss: 0.6833, Test Accuracy: 0.5786\n",
            "Epoch: 5, Train Loss: 0.6811, Test Accuracy: 0.5786\n",
            "Epoch: 6, Train Loss: 0.6823, Test Accuracy: 0.5786\n",
            "Epoch: 7, Train Loss: 0.6828, Test Accuracy: 0.5786\n",
            "Epoch: 8, Train Loss: 0.6829, Test Accuracy: 0.5786\n",
            "Epoch: 9, Train Loss: 0.6826, Test Accuracy: 0.5786\n",
            "Epoch: 10, Train Loss: 0.6841, Test Accuracy: 0.5786\n",
            "Final Test Accuracy with k1=0.9, k2=0.8: 0.5786\n",
            "\n",
            "k1 = 0.9 and k2 = 0.6\n",
            "Epoch: 1, Train Loss: 0.7319, Test Accuracy: 0.5786\n",
            "Epoch: 2, Train Loss: 0.6831, Test Accuracy: 0.5786\n",
            "Epoch: 3, Train Loss: 0.6828, Test Accuracy: 0.5786\n",
            "Epoch: 4, Train Loss: 0.6827, Test Accuracy: 0.5786\n",
            "Epoch: 5, Train Loss: 0.6822, Test Accuracy: 0.5786\n",
            "Epoch: 6, Train Loss: 0.6835, Test Accuracy: 0.5786\n",
            "Epoch: 7, Train Loss: 0.6826, Test Accuracy: 0.5786\n",
            "Epoch: 8, Train Loss: 0.6821, Test Accuracy: 0.5786\n",
            "Epoch: 9, Train Loss: 0.6823, Test Accuracy: 0.5786\n",
            "Epoch: 10, Train Loss: 0.6826, Test Accuracy: 0.5786\n",
            "Final Test Accuracy with k1=0.9, k2=0.6: 0.5786\n",
            "\n",
            "k1 = 0.8 and k2 = 0.9\n",
            "Epoch: 1, Train Loss: 0.6911, Test Accuracy: 0.5786\n",
            "Epoch: 2, Train Loss: 0.6826, Test Accuracy: 0.5786\n",
            "Epoch: 3, Train Loss: 0.6828, Test Accuracy: 0.5786\n",
            "Epoch: 4, Train Loss: 0.6833, Test Accuracy: 0.5786\n",
            "Epoch: 5, Train Loss: 0.6821, Test Accuracy: 0.5786\n",
            "Epoch: 6, Train Loss: 0.6824, Test Accuracy: 0.5786\n",
            "Epoch: 7, Train Loss: 0.6826, Test Accuracy: 0.5786\n",
            "Epoch: 8, Train Loss: 0.6829, Test Accuracy: 0.5786\n",
            "Epoch: 9, Train Loss: 0.6825, Test Accuracy: 0.5786\n",
            "Epoch: 10, Train Loss: 0.6831, Test Accuracy: 0.5786\n",
            "Final Test Accuracy with k1=0.8, k2=0.9: 0.5786\n",
            "\n",
            "k1 = 0.8 and k2 = 0.6\n",
            "Epoch: 1, Train Loss: 0.7390, Test Accuracy: 0.5786\n",
            "Epoch: 2, Train Loss: 0.6833, Test Accuracy: 0.5786\n",
            "Epoch: 3, Train Loss: 0.6822, Test Accuracy: 0.5786\n",
            "Epoch: 4, Train Loss: 0.6827, Test Accuracy: 0.5786\n",
            "Epoch: 5, Train Loss: 0.6830, Test Accuracy: 0.5786\n",
            "Epoch: 6, Train Loss: 0.6835, Test Accuracy: 0.5786\n",
            "Epoch: 7, Train Loss: 0.6827, Test Accuracy: 0.5786\n",
            "Epoch: 8, Train Loss: 0.6817, Test Accuracy: 0.5786\n",
            "Epoch: 9, Train Loss: 0.6833, Test Accuracy: 0.5786\n",
            "Epoch: 10, Train Loss: 0.6829, Test Accuracy: 0.5786\n",
            "Final Test Accuracy with k1=0.8, k2=0.6: 0.5786\n",
            "\n",
            "k1 = 0.6 and k2 = 0.9\n",
            "Epoch: 1, Train Loss: 0.9125, Test Accuracy: 0.5786\n",
            "Epoch: 2, Train Loss: 0.6826, Test Accuracy: 0.5786\n",
            "Epoch: 3, Train Loss: 0.6821, Test Accuracy: 0.5786\n",
            "Epoch: 4, Train Loss: 0.6832, Test Accuracy: 0.5786\n",
            "Epoch: 5, Train Loss: 0.6828, Test Accuracy: 0.5786\n",
            "Epoch: 6, Train Loss: 0.6829, Test Accuracy: 0.5786\n",
            "Epoch: 7, Train Loss: 0.6821, Test Accuracy: 0.5786\n",
            "Epoch: 8, Train Loss: 0.6826, Test Accuracy: 0.5786\n",
            "Epoch: 9, Train Loss: 0.6824, Test Accuracy: 0.5786\n",
            "Epoch: 10, Train Loss: 0.6828, Test Accuracy: 0.5786\n",
            "Final Test Accuracy with k1=0.6, k2=0.9: 0.5786\n",
            "\n",
            "k1 = 0.6 and k2 = 0.8\n",
            "Epoch: 1, Train Loss: 0.6807, Test Accuracy: 0.5786\n",
            "Epoch: 2, Train Loss: 0.6824, Test Accuracy: 0.5786\n",
            "Epoch: 3, Train Loss: 0.6833, Test Accuracy: 0.5786\n",
            "Epoch: 4, Train Loss: 0.6834, Test Accuracy: 0.5786\n",
            "Epoch: 5, Train Loss: 0.6817, Test Accuracy: 0.5786\n",
            "Epoch: 6, Train Loss: 0.6816, Test Accuracy: 0.5786\n",
            "Epoch: 7, Train Loss: 0.6822, Test Accuracy: 0.5786\n",
            "Epoch: 8, Train Loss: 0.6817, Test Accuracy: 0.5786\n",
            "Epoch: 9, Train Loss: 0.6826, Test Accuracy: 0.5786\n",
            "Epoch: 10, Train Loss: 0.6831, Test Accuracy: 0.5786\n",
            "Final Test Accuracy with k1=0.6, k2=0.8: 0.5786\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_metrics(metrics, k_values):\n",
        "  for k1, metric in metrics.items():\n",
        "    plt.plot(metric['epoch'], metric['accuracy'], label=f'k1={k1}')\n",
        "  plt.xlabel('Epochs')\n",
        "  plt.ylabel('Accuracy')\n",
        "  plt.title('Test Accuracy over Epochs')\n",
        "  plt.legend()\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "mK88Xaw-FKPW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "\n",
        "# Convert results into a 2D matrix for plotting\n",
        "accuracy_matrix = np.array([\n",
        "    [results[(k1, k2)] for k2 in k_values]\n",
        "    for k1 in k_values\n",
        "])\n",
        "\n",
        "# Create a heatmap using seaborn\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(accuracy_matrix, annot=True, cmap=\"YlGnBu\", xticklabels=k_values, yticklabels=k_values)\n",
        "\n",
        "plt.title(\"k1, k2 vs Accuracy\")\n",
        "plt.xlabel(\"k2 Values\")\n",
        "plt.ylabel(\"k1 Values\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "NJXS4WmjPTl0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 371
        },
        "outputId": "2bcfde59-c316-4ad8-8060-b2539694fed4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "(0.9, 0.9)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-2dcd74bd7ab3>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Convert results into a 2D matrix for plotting\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m accuracy_matrix = np.array([\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0;34m[\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk2\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mk_values\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mk1\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mk_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-23-2dcd74bd7ab3>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Convert results into a 2D matrix for plotting\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m accuracy_matrix = np.array([\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0;34m[\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk2\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mk_values\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mk1\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mk_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m ])\n",
            "\u001b[0;32m<ipython-input-23-2dcd74bd7ab3>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Convert results into a 2D matrix for plotting\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m accuracy_matrix = np.array([\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0;34m[\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk2\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mk_values\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mk1\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mk_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m ])\n",
            "\u001b[0;31mKeyError\u001b[0m: (0.9, 0.9)"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ENZYME dataset"
      ],
      "metadata": {
        "id": "yEd64vg75-ka"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the ENZYMES dataset\n",
        "dataset = TUDataset(root='/tmp/ENZYMES', name='ENZYMES')\n",
        "# Print dataset information\n",
        "print(f\"Number of graphs: {len(dataset)}\")\n",
        "print(f\"Number of classes: {dataset.num_classes}\")\n",
        "print(f\"Number of node features: {dataset.num_node_features}\")\n",
        "\n",
        "# Access a single graph\n",
        "data = dataset[0]  # Get the first graph example\n",
        "print(data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2cclCTC16iHP",
        "outputId": "53d447b3-4284-4d72-e984-f36de39f74e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading https://www.chrsmrrs.com/graphkerneldatasets/ENZYMES.zip\n",
            "Processing...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of graphs: 600\n",
            "Number of classes: 6\n",
            "Number of node features: 3\n",
            "Data(edge_index=[2, 168], x=[37, 3], y=[1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Done!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_size = int(0.8 * len(dataset))\n",
        "test_size = len(dataset) - train_size\n",
        "train_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, test_size])\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=3, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=3, shuffle=False)"
      ],
      "metadata": {
        "id": "AljoAVw860ga"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import GCNConv, TopKPooling, global_mean_pool\n",
        "\n",
        "class DiffPoolLayer(torch.nn.Module):\n",
        "  def __init__(self, in_channels, hidden_channels, num_clusters):\n",
        "    super(DiffPoolLayer, self).__init__()\n",
        "    # GNN for learning node embeddings\n",
        "    self.gnn_embed = GCNConv(in_channels, hidden_channels)\n",
        "    # GNN for learning cluster assignments\n",
        "    self.gnn_assign = GCNConv(in_channels, num_clusters)\n",
        "\n",
        "  def forward(self, x, edge_index, batch):\n",
        "    # Learn node embeddings\n",
        "    h = F.relu(self.gnn_embed(x, edge_index))\n",
        "    # Learn assignment matrix (cluster assignments)\n",
        "    s = torch.softmax(self.gnn_assign(x, edge_index), dim=-1)\n",
        "\n",
        "    # Pooling: Aggregate node features into clusters\n",
        "    x_pooled = torch.matmul(s.T, h)  # (num_clusters, hidden_channels)\n",
        "\n",
        "    # New adjacency matrix after coarsening\n",
        "    adj_pooled = torch.matmul(s.T, s)  # (num_clusters, num_clusters)\n",
        "\n",
        "    # Reconstruct edge_index from pooled adjacency matrix\n",
        "    edge_index_pooled = (adj_pooled > 0).nonzero(as_tuple=False).T\n",
        "\n",
        "    # Batch update: assume each cluster belongs to the same graph as the original nodes\n",
        "    num_graphs = batch.max().item() + 1\n",
        "    clusters_per_graph = max(1, s.shape[1] // num_graphs)\n",
        "\n",
        "    batch_pooled = torch.repeat_interleave(torch.arange(num_graphs), clusters_per_graph)[:s.shape[1]]\n",
        "\n",
        "    #batch_pooled = torch.repeat_interleave(torch.arange(batch.max() + 1), s.shape[1] // (batch.max() + 1))\n",
        "    #assert x.size(0) == batch.max().item() + 1, \"Batch size mismatch!\"\n",
        "    if (batch_pooled.size() == 2):\n",
        "      batch_pooled += 1\n",
        "    return x_pooled, edge_index_pooled, batch_pooled\n",
        "\n",
        "class GraphClassificationModel(torch.nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, num_classes, m1, m2, k1=0.2, k2=0.1):\n",
        "      super(GraphClassificationModel, self).__init__()\n",
        "\n",
        "      # GNN Layers\n",
        "      self.gnn1 = GCNConv(input_dim, hidden_dim)\n",
        "      self.gnn2 = GCNConv(hidden_dim, hidden_dim)\n",
        "\n",
        "      # gPool Layer 1\n",
        "      self.pool1 = TopKPooling(hidden_dim, ratio=k1)\n",
        "\n",
        "      # DiffPool Layer 1\n",
        "      self.diffpool1 = DiffPoolLayer(hidden_dim, hidden_dim, m1)\n",
        "\n",
        "      self.gnn3 = GCNConv(hidden_dim, hidden_dim)\n",
        "      self.gnn4 = GCNConv(hidden_dim, hidden_dim)\n",
        "\n",
        "      # gPool Layer 2\n",
        "      self.pool2 = TopKPooling(hidden_dim, ratio=k2)\n",
        "\n",
        "      # DiffPool Layer 2\n",
        "      self.diffpool2 = DiffPoolLayer(hidden_dim, hidden_dim, m2)\n",
        "\n",
        "      # Final classification layer\n",
        "      self.fc = torch.nn.Linear(hidden_dim, num_classes)\n",
        "\n",
        "    def forward(self, data):\n",
        "      x, edge_index, batch = data.x, data.edge_index, data.batch\n",
        "\n",
        "      # Initial GNN Layers\n",
        "      x = F.relu(self.gnn1(x, edge_index))\n",
        "      x = F.relu(self.gnn2(x, edge_index))\n",
        "      # print(f\"Starting: x size = {x.size()}, batch size = {batch.size()}\")\n",
        "      # print(\"-------------------------------------\")\n",
        "      # gPool Layer 1\n",
        "      # Modified: Unpack only the necessary values\n",
        "      x, edge_index, _, batch, perm, score = self.pool1(x, edge_index, None, batch)\n",
        "      # print(f\"After gpool1: x size = {x.size()}, batch size = {batch.size()}\")\n",
        "      # print(\"-------------------------------------\")\n",
        "      # print(f\"batch size: {batch.size()}, perm size: {perm.size()}\")\n",
        "      # print(f\"max(perm): {perm.max()}, len(batch): {len(batch)}\")\n",
        "      if perm.size(0) > 0:\n",
        "        perm = perm[perm < batch.size(0)]\n",
        "        batch = batch[perm]  # Update batch after pooling\n",
        "\n",
        "      # DiffPool Layer 1\n",
        "      x, edge_index, batch = self.diffpool1(x, edge_index, batch)\n",
        "      # print(f\"After diffpool1: x size = {x.size()}, batch size = {batch.size()}\")\n",
        "      # print(\"-------------------------------------\")\n",
        "\n",
        "      # Additional GNN Layers\n",
        "      x = F.relu(self.gnn3(x, edge_index))\n",
        "      x = F.relu(self.gnn4(x, edge_index))\n",
        "\n",
        "      # gPool Layer 2\n",
        "      # Modified: Unpack only the necessary values\n",
        "      #print(f\"After DiffPool: x size = {x.size()}, batch size = {batch.size()}\")\n",
        "\n",
        "      x, edge_index, _, batch, perm, score = self.pool2(x, edge_index, None, batch)\n",
        "      # print(f\"After gpool2: x size = {x.size()}, batch size = {batch.size()}\")\n",
        "      # print(\"-------------------------------------\")\n",
        "      # print(f\"batch size: {batch.size()}, perm size: {perm.size()}\")\n",
        "      # print(f\"max(perm): {perm.max()}, len(batch): {len(batch)}\")\n",
        "      # perm = perm[perm < batch.size(0)]\n",
        "      # batch = batch[perm]  # Update batch after pooling\n",
        "\n",
        "      # # DiffPool Layer 2\n",
        "      # x, edge_index, batch = self.diffpool2(x, edge_index, batch)\n",
        "\n",
        "      # # Global Pooling for graph-level embedding\n",
        "      # x = global_mean_pool(x, batch)\n",
        "\n",
        "       # Check for empty graphs after pooling\n",
        "      if batch.size(0) == 0:\n",
        "          # Handle empty graphs (e.g., skip or assign a default output)\n",
        "          # For example, you could return a zero vector for these graphs:\n",
        "          print(\"graph is empty\")\n",
        "          x = torch.zeros(1, self.hidden_dim, device=x.device)\n",
        "          batch = torch.zeros(1, dtype=torch.long, device=x.device)\n",
        "\n",
        "      else:\n",
        "\n",
        "          perm = perm[perm < batch.size(0)]\n",
        "          batch = batch[perm]  # Update batch after pooling\n",
        "\n",
        "      # DiffPool Layer 2\n",
        "      x, edge_index, batch = self.diffpool2(x, edge_index, batch)\n",
        "      # print(f\"After diffpool2: x size = {x.size()}, batch size = {batch.size()}\")\n",
        "      # print(\"-------------------------------------\")\n",
        "\n",
        "\n",
        "\n",
        "      # Global Pooling for graph-level embedding\n",
        "      x = global_mean_pool(x, batch)\n",
        "      # print(f\"After globalmean: x size = {x.size()}, batch size = {batch.size()}\")\n",
        "\n",
        "      # Final Classification Head\n",
        "      x = self.fc(x)\n",
        "      #print(f\"After fc: x size = {x.size()}, batch size = {batch.size()}\")\n",
        "      #print(F.log_softmax(x, dim=1))\n",
        "      return F.log_softmax(x, dim=1)\n"
      ],
      "metadata": {
        "id": "ShfVHBbW76fu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the model with specific hyperparameters\n",
        "model = GraphClassificationModel(\n",
        "    input_dim=dataset.num_node_features,\n",
        "    hidden_dim=64,  # Adjust as needed\n",
        "    num_classes=dataset.num_classes, # 6\n",
        "    m1=6,  # First DiffPool with 6 clusters\n",
        "    m2=3,  # Second DiffPool with 3 clusters\n",
        "    k1=0.9,  # 90% top nodes kept in first gPool layer\n",
        "    k2=0.8   # 80% top nodes kept in second gPool layer\n",
        ")\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "for epoch in range(1, 31):\n",
        "  train_loss = train(model, train_loader, optimizer, criterion)\n",
        "  train_acc = test(model, train_loader)\n",
        "  #test_acc = test(model, test_loader)\n",
        "  print(f'Epoch: {epoch}, Train Loss: {train_loss:.4f}, Test Accuracy: {train_acc:.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XfGEpMOl7xYB",
        "outputId": "f1af18e8-a94d-4868-8da8-712733f4ed76"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1, Train Loss: 1.8105, Test Accuracy: 0.1771\n",
            "Epoch: 2, Train Loss: 1.7975, Test Accuracy: 0.1771\n",
            "Epoch: 3, Train Loss: 1.7959, Test Accuracy: 0.1771\n",
            "Epoch: 4, Train Loss: 1.7961, Test Accuracy: 0.1771\n",
            "Epoch: 5, Train Loss: 1.7955, Test Accuracy: 0.1771\n",
            "Epoch: 6, Train Loss: 1.7969, Test Accuracy: 0.1771\n",
            "Epoch: 7, Train Loss: 1.7955, Test Accuracy: 0.1771\n",
            "Epoch: 8, Train Loss: 1.7976, Test Accuracy: 0.1771\n",
            "Epoch: 9, Train Loss: 1.7962, Test Accuracy: 0.1667\n",
            "Epoch: 10, Train Loss: 1.7955, Test Accuracy: 0.1771\n",
            "Epoch: 11, Train Loss: 1.7966, Test Accuracy: 0.1771\n",
            "Epoch: 12, Train Loss: 1.7974, Test Accuracy: 0.1771\n",
            "Epoch: 13, Train Loss: 1.7959, Test Accuracy: 0.1771\n",
            "Epoch: 14, Train Loss: 1.7959, Test Accuracy: 0.1771\n",
            "Epoch: 15, Train Loss: 1.7968, Test Accuracy: 0.1771\n",
            "Epoch: 16, Train Loss: 1.7983, Test Accuracy: 0.1771\n",
            "Epoch: 17, Train Loss: 1.7967, Test Accuracy: 0.1771\n",
            "Epoch: 18, Train Loss: 1.7951, Test Accuracy: 0.1771\n",
            "Epoch: 19, Train Loss: 1.7960, Test Accuracy: 0.1771\n",
            "Epoch: 20, Train Loss: 1.7967, Test Accuracy: 0.1771\n",
            "Epoch: 21, Train Loss: 1.7969, Test Accuracy: 0.1771\n",
            "Epoch: 22, Train Loss: 1.7955, Test Accuracy: 0.1771\n",
            "Epoch: 23, Train Loss: 1.7974, Test Accuracy: 0.1771\n",
            "Epoch: 24, Train Loss: 1.7965, Test Accuracy: 0.1771\n",
            "Epoch: 25, Train Loss: 1.7968, Test Accuracy: 0.1771\n",
            "Epoch: 26, Train Loss: 1.7947, Test Accuracy: 0.1771\n",
            "Epoch: 27, Train Loss: 1.7960, Test Accuracy: 0.1688\n",
            "Epoch: 28, Train Loss: 1.7967, Test Accuracy: 0.1771\n",
            "Epoch: 29, Train Loss: 1.7966, Test Accuracy: 0.1771\n",
            "Epoch: 30, Train Loss: 1.7959, Test Accuracy: 0.1771\n"
          ]
        }
      ]
    }
  ]
}